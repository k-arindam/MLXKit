{"sections":[],"schemaVersion":{"minor":3,"major":0,"patch":0},"metadata":{"externalID":"s:6MLXKit7softmaxySaySfGACF","modules":[{"name":"MLXKit"}],"symbolKind":"func","roleHeading":"Function","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"softmax"},{"kind":"text","text":"(["},{"kind":"typeIdentifier","text":"Float","preciseIdentifier":"s:Sf"},{"kind":"text","text":"]) -> ["},{"kind":"typeIdentifier","text":"Float","preciseIdentifier":"s:Sf"},{"kind":"text","text":"]"}],"role":"symbol","title":"softmax(_:)"},"kind":"symbol","identifier":{"url":"doc:\/\/MLXKit\/documentation\/MLXKit\/softmax(_:)","interfaceLanguage":"swift"},"abstract":[{"text":"Computes the “softmax” function over an array.","type":"text"}],"primaryContentSections":[{"kind":"declarations","declarations":[{"tokens":[{"text":"func","kind":"keyword"},{"text":" ","kind":"text"},{"text":"softmax","kind":"identifier"},{"text":"(","kind":"text"},{"text":"_","kind":"externalParam"},{"text":" ","kind":"text"},{"text":"x","kind":"internalParam"},{"text":": [","kind":"text"},{"text":"Float","kind":"typeIdentifier","preciseIdentifier":"s:Sf"},{"text":"]) -> [","kind":"text"},{"text":"Float","kind":"typeIdentifier","preciseIdentifier":"s:Sf"},{"text":"]","kind":"text"}],"languages":["swift"],"platforms":["macOS"]}]},{"kind":"content","content":[{"type":"heading","text":"Discussion","anchor":"discussion","level":2},{"type":"paragraph","inlineContent":[{"text":"Based on code from https:\/\/github.com\/nikolaypavlov\/MLPNeuralNet\/","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"This is what softmax looks like in “pseudocode” (actually using Python"},{"type":"text","text":" "},{"type":"text","text":"and numpy):"}]},{"type":"codeListing","code":["x -= np.max(x)","exp_scores = np.exp(x)","softmax = exp_scores \/ np.sum(exp_scores)"],"syntax":null},{"type":"paragraph","inlineContent":[{"type":"text","text":"First we shift the values of x so that the highest value in the array is 0."},{"type":"text","text":" "},{"type":"text","text":"This ensures numerical stability with the exponents, so they don’t blow up."}]}]}],"variants":[{"paths":["\/documentation\/mlxkit\/softmax(_:)"],"traits":[{"interfaceLanguage":"swift"}]}],"hierarchy":{"paths":[["doc:\/\/MLXKit\/documentation\/MLXKit"]]},"references":{"doc://MLXKit/documentation/MLXKit/softmax(_:)":{"identifier":"doc:\/\/MLXKit\/documentation\/MLXKit\/softmax(_:)","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"softmax"},{"kind":"text","text":"(["},{"preciseIdentifier":"s:Sf","kind":"typeIdentifier","text":"Float"},{"kind":"text","text":"]) -> ["},{"preciseIdentifier":"s:Sf","kind":"typeIdentifier","text":"Float"},{"kind":"text","text":"]"}],"type":"topic","kind":"symbol","url":"\/documentation\/mlxkit\/softmax(_:)","title":"softmax(_:)","abstract":[{"text":"Computes the “softmax” function over an array.","type":"text"}],"role":"symbol"},"doc://MLXKit/documentation/MLXKit":{"abstract":[],"role":"collection","identifier":"doc:\/\/MLXKit\/documentation\/MLXKit","kind":"symbol","url":"\/documentation\/mlxkit","type":"topic","title":"MLXKit"}}}